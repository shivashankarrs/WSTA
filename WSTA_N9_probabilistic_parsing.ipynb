{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic CFG parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the process behind parsing with a probabilistic (weighted) context free grammar. The algorithm here is based on the CYK algorithm for PCFG parsing, as described in Figure 14.3 J&M2 and presented in the lecture. Note that NLTK implements a few probabilistic parsing methods internally, which are a little different to the algorithm presented in the lecture but are an excellent resource (see pointer at the bottom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.grammar\n",
    "from collections import defaultdict\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a warm-up let's start by creating a standard (unweighted) CFG grammar and parse a simple sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'a' | 'an' | 'my' | 'the' \n",
    "N -> 'elephant' | 'pajamas' | 'shot'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sentence is chosen to be ambiguous, note that there are two ways in which the following can be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "trees = list(parser.parse(sent))\n",
    "print(len(trees))\n",
    "print(trees[0])\n",
    "print(trees[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These trees can be visualised in a more comprehensible way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\tree.pyc\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_widget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             subprocess.call([find_binary('gs', binary_names=['gswin32c.exe', 'gswin64c.exe'], env_vars=['PATH'], verbose=False)] +\n\u001b[0m\u001b[1;32m    727\u001b[0m                             \u001b[1;34m'-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile={0:} {1:}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                             .format(out_path, in_path).split())\n",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\__init__.pyc\u001b[0m in \u001b[0;36mfind_binary\u001b[0;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[1;32m    600\u001b[0m                 binary_names=None, url=None, verbose=True):\n\u001b[1;32m    601\u001b[0m     return next(find_binary_iter(name, path_to_bin, env_vars, searchpath,\n\u001b[0;32m--> 602\u001b[0;31m                                  binary_names, url, verbose))\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m def find_jar_iter(name_pattern, path_to_jar=None, env_vars=(),\n",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\__init__.pyc\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[0;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \"\"\"\n\u001b[1;32m    595\u001b[0m     for file in  find_file_iter(path_to_bin or name, env_vars, searchpath, binary_names,\n\u001b[0;32m--> 596\u001b[0;31m                      url, verbose):\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\__init__.pyc\u001b[0m in \u001b[0;36mfind_file_iter\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[1;32m    565\u001b[0m                         (filename, url))\n\u001b[1;32m    566\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n==========================================================================="
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('NP', ['I']), Tree('VP', [Tree('VP', [Tree('V', ['shot']), Tree('NP', [Tree('Det', ['an']), Tree('N', ['elephant'])])]), Tree('PP', [Tree('P', ['in']), Tree('NP', [Tree('Det', ['my']), Tree('N', ['pajamas'])])])])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a lot of warnings in the above, and no pretty tree, then that means you're missing the *ghostview* library. It comes standard with linux and mac, I think, but you may need to install it yourself on windows. You can obtain a copy of the GPL binary [from the ghostview website](http://www.ghostscript.com/download/gsdnld.html). If you're on a locked-down machine, and can't install, you may want to view the tree as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S                                       \n",
      "  ___|______________                          \n",
      " |                  VP                       \n",
      " |         _________|__________               \n",
      " |        VP                   PP            \n",
      " |    ____|___              ___|___           \n",
      " |   |        NP           |       NP        \n",
      " |   |     ___|_____       |    ___|_____     \n",
      " NP  V   Det        N      P  Det        N   \n",
      " |   |    |         |      |   |         |    \n",
      " I  shot  an     elephant  in  my     pajamas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ASCII art\n",
    "trees[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-81e599567e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# launches a popup window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrees\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\tree.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \"\"\"\n\u001b[1;32m    685\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mdraw_trees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\draw\\tree.pyc\u001b[0m in \u001b[0;36mdraw_trees\u001b[0;34m(*trees)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     \"\"\"\n\u001b[0;32m--> 866\u001b[0;31m     \u001b[0mTreeView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\nltk\\draw\\tree.pyc\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \"\"\"\n\u001b[1;32m    856\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0min_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shivashankar\\AppData\\Local\\Continuum\\Anaconda2\\lib\\lib-tk\\Tkinter.pyc\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[1;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# launches a popup window\n",
    "trees[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the other tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will move to a PCFG, where each rule has a weight denoted by a bracket [number] after each production. Here's a fairly simple (different) grammar, which we will use to develop and demonstrate the CYK parsing algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_pcfg2 = nltk.grammar.PCFG.fromstring(\"\"\"\n",
    "    S    -> NP VP         [1.0]\n",
    "    VP   -> V NP          [.59]\n",
    "    VP   -> V             [.40]\n",
    "    VP   -> VP PP         [.01]\n",
    "    NP   -> Det N         [.41]\n",
    "    NP   -> Name          [.28]\n",
    "    NP   -> NP PP         [.31]\n",
    "    PP   -> P NP          [1.0]\n",
    "    V    -> 'saw'         [.21]\n",
    "    V    -> 'ate'         [.51]\n",
    "    V    -> 'ran'         [.28]\n",
    "    N    -> 'boy'         [.11]\n",
    "    N    -> 'cookie'      [.12]\n",
    "    N    -> 'table'       [.13]\n",
    "    N    -> 'telescope'   [.14]\n",
    "    N    -> 'hill'        [.5]\n",
    "    Name -> 'Jack'        [.52]\n",
    "    Name -> 'Bob'         [.48]\n",
    "    P    -> 'with'        [.61]\n",
    "    P    -> 'under'       [.39]\n",
    "    Det  -> 'the'         [.41]\n",
    "    Det  -> 'a'           [.31]\n",
    "    Det  -> 'my'          [.28]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to check that the grammar is in Chomsky normal form (CNF), as this is a condition for using the CYK parsing algorithm. Recall that CNF means that all rules are either X -> A B or X -> 'word', where capitals denote non-terminal symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(toy_pcfg2.is_chomsky_normal_form())\n",
    "print(toy_pcfg2.is_flexible_chomsky_normal_form())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope. This is because of the unary productions X -> Y. Note that these can cause problems, especially when there is a loop (NP -> PP -> NP ...). This means the grammar can produce infinitely deep trees, and generally makes the algorithm more complex, as we would have to reduce the grammar to CNF by solving the total probability over any length chain. Note that as the probability of each production is bounded, $0 \\le p \\le 1$, long chains tend to be increasingly improbable.  However note that our grammar has no unary cycles, so we can ignore this problem. *Do you have any ideas on how this might be handled properly, in general?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interact with the grammar in several ways. Have a little play below, e.g., to lookup a production and query its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21\n",
      "V\n",
      "[VP -> V NP [0.59], VP -> V [0.4]]\n"
     ]
    }
   ],
   "source": [
    "p = toy_pcfg2.productions(rhs='saw')[0]\n",
    "print(p.prob())\n",
    "print(p.lhs())\n",
    "q = toy_pcfg2.productions(rhs=p.lhs())\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the CYK parsing algorithm. This operates by incrementally constructing a *chart (table)* using dynamic programming. The chart stores the partial results thus far, which encodes the best scoring tree structure for substrings of the input sentence. These partial results are extended incrementally to find the best scoring structure for the whole sentence.\n",
    "\n",
    "Recall that a sentence is indexed by the spaces between words, e.g.,\n",
    "\n",
    "        0 this 1 is 2 an 3 example 4\n",
    "        \n",
    "such that words or strings of words can be represented as a pair of [start, end] indices. E.g., [2,3] = an; [1,4] = is an example. Each element in the chart is indexed as:\n",
    "\n",
    "        table[i, j][non-terminal]\n",
    "        \n",
    "which stores a probability for parsing the string [i, j]. The CYK algorithm builds these from smaller units by searching for all i < k < j and all productions such that previous analyses that cover [i,k] and [k,j] might be combined using a binary production to cover [i,j]. For this to be valid, the symbols for the two spans must match the RHS of a production in the grammar, and the resulting non-terminal is the LHS of the production. \n",
    "\n",
    "You'll need to read J&M2 and the lecture slides for more details, or tinker with the code below to understand the process. (E.g., by adding a display call into the j loop.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_CYK(words, grammar):\n",
    "    table = defaultdict(dict)    \n",
    "    back = defaultdict(dict)\n",
    "    \n",
    "    # righter-most index j\n",
    "    for j in range(1, len(words)+1):\n",
    "        # insert token preterminal rewrites, POS -> 'word'\n",
    "        token = words[j-1]\n",
    "        for prod in grammar.productions(rhs=token):\n",
    "            if len(prod.rhs()) == 1:\n",
    "                table[j-1,j][prod.lhs()] = prod.prob()\n",
    "\n",
    "        # deal with pesky unary productions \n",
    "        changes = True\n",
    "        cell = table[j-1,j]\n",
    "        while changes:\n",
    "            # repeat this loop until no rule changes; will infinitely\n",
    "            # loop for grammars with a unary cycle\n",
    "            changes = False\n",
    "            for non_term in list(cell.keys()):\n",
    "                prob = cell[non_term]\n",
    "                for prod in grammar.productions(rhs=non_term):\n",
    "                    if len(prod.rhs()) == 1:\n",
    "                        unary_prob = prod.prob() * prob\n",
    "                        if unary_prob > cell.get(prod.lhs(), 0):\n",
    "                            cell[prod.lhs()] = unary_prob\n",
    "                            back[j-1,j][prod.lhs()] = (None, prod)\n",
    "                            changes = True\n",
    "        \n",
    "        # now look for larger productions that span [i, j]\n",
    "        # allowing i to move leftward over the input\n",
    "        for i in range(j-2, -1, -1):\n",
    "            cell = table[i,j]\n",
    "            # k is the split point, i < k < j\n",
    "            for k in range(i+1, j):\n",
    "                # find chart cells based on the split point\n",
    "                left_cell = table[i,k]\n",
    "                right_cell = table[k,j]\n",
    "                # find binary productions which handle a valid symbol A from left cell, X -> A B\n",
    "                for left_nt, left_prob in left_cell.items():\n",
    "                    for prod in grammar.productions(rhs=left_nt):\n",
    "                        if len(prod.rhs()) == 2:\n",
    "                            # check if the left and right cells have a valid parse\n",
    "                            right_prob = right_cell.get(prod.rhs()[1])\n",
    "                            if left_prob != None and right_prob != None:\n",
    "                                # score the partial parse\n",
    "                                prob = prod.prob() * left_prob * right_prob\n",
    "                                if prob > cell.get(prod.lhs(), 0.0):\n",
    "                                    # if it exceeds the current best analysis, update the cell\n",
    "                                    cell[prod.lhs()] = prob\n",
    "                                    # and store a record of how we got here\n",
    "                                    back[i,j][prod.lhs()] = (k, prod)\n",
    "    \n",
    "    # display the table and back pointers\n",
    "    display_CYK_chart(words, table, back)\n",
    "\n",
    "    # have to build the tree from the back pointers\n",
    "    return build_tree(words, back, grammar.start(), i=0, j=len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to write the remaining functions. First creating the tree from the back-pointers, which operates recursively starting at the word sentence headed by the start symbol 'S' (i.e., cell [0, length, S]). Then it follows the back pointers to find where the span was split and what the child symbols were.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree(words, back, symbol, i, j):\n",
    "    backpointer = back[i, j].get(symbol)\n",
    "    if backpointer == None:\n",
    "        # X -> 'word' production\n",
    "        assert j == i+1\n",
    "        return nltk.tree.Tree(symbol, [words[i]])\n",
    "    else:\n",
    "        k, prod = back[i, j][symbol]\n",
    "        if k != None:\n",
    "            # X -> A B binary production\n",
    "            left_subtree = build_tree(words, back, prod.rhs()[0], i=i, j=k)\n",
    "            right_subtree = build_tree(words, back, prod.rhs()[1], i=k, j=j)\n",
    "            return nltk.tree.Tree(symbol, [left_subtree, right_subtree])\n",
    "        else:\n",
    "            # X -> A unary production\n",
    "            subtree = build_tree(words, back, prod.rhs()[0], i=i, j=j)\n",
    "            return nltk.tree.Tree(symbol, [subtree])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some pretty printing code to view the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_CYK_chart(words, table, back):\n",
    "    length = len(words)\n",
    "    html = ''\n",
    "    html += '<tr>'\n",
    "    for i in range(length):\n",
    "        html += '<td><i>%s<i></td>' % words[i]\n",
    "    html += '</tr>'\n",
    "    for i in range(length):\n",
    "        html += '<tr>'\n",
    "        for j in range(1, length+1):\n",
    "            if j <= i:\n",
    "                html += '<td>'\n",
    "            else:\n",
    "                html += \"<td bgcolor='lightcyan'>\"\n",
    "                html += '[%d,%d]' % (i,j) \n",
    "                for symbol, prob in table.get((i,j), {}).items():\n",
    "                    html += '<br><b>%s</b> [%.5f]' % (str(symbol), prob)\n",
    "                    b = back[i,j].get(symbol)\n",
    "                    if b != None:\n",
    "                        html += '<br>&nbsp; (k=%s, %s)' % (b[0], str(b[1]))\n",
    "            html += '</td>'\n",
    "        html += '</tr>'\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are ready to parse! Let's set it loose on a simple sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr><td><i>Jack<i></td><td><i>saw<i></td><td><i>Bob<i></td><td><i>with<i></td><td><i>my<i></td><td><i>cookie<i></td></tr><tr><td bgcolor='lightcyan'>[0,1]<br><b>NP</b> [0.14560]<br>&nbsp; (k=None, NP -> Name [0.28])<br><b>Name</b> [0.52000]</td><td bgcolor='lightcyan'>[0,2]<br><b>S</b> [0.01223]<br>&nbsp; (k=1, S -> NP VP [1.0])</td><td bgcolor='lightcyan'>[0,3]<br><b>S</b> [0.00242]<br>&nbsp; (k=1, S -> NP VP [1.0])</td><td bgcolor='lightcyan'>[0,4]</td><td bgcolor='lightcyan'>[0,5]</td><td bgcolor='lightcyan'>[0,6]<br><b>S</b> [0.00001]<br>&nbsp; (k=1, S -> NP VP [1.0])</td></tr><tr><td></td><td bgcolor='lightcyan'>[1,2]<br><b>VP</b> [0.08400]<br>&nbsp; (k=None, VP -> V [0.4])<br><b>V</b> [0.21000]</td><td bgcolor='lightcyan'>[1,3]<br><b>VP</b> [0.01665]<br>&nbsp; (k=2, VP -> V NP [0.59])</td><td bgcolor='lightcyan'>[1,4]</td><td bgcolor='lightcyan'>[1,5]</td><td bgcolor='lightcyan'>[1,6]<br><b>VP</b> [0.00004]<br>&nbsp; (k=2, VP -> V NP [0.59])</td></tr><tr><td></td><td></td><td bgcolor='lightcyan'>[2,3]<br><b>NP</b> [0.13440]<br>&nbsp; (k=None, NP -> Name [0.28])<br><b>Name</b> [0.48000]</td><td bgcolor='lightcyan'>[2,4]</td><td bgcolor='lightcyan'>[2,5]</td><td bgcolor='lightcyan'>[2,6]<br><b>NP</b> [0.00035]<br>&nbsp; (k=3, NP -> NP PP [0.31])</td></tr><tr><td></td><td></td><td></td><td bgcolor='lightcyan'>[3,4]<br><b>P</b> [0.61000]</td><td bgcolor='lightcyan'>[3,5]</td><td bgcolor='lightcyan'>[3,6]<br><b>PP</b> [0.00840]<br>&nbsp; (k=4, PP -> P NP [1.0])</td></tr><tr><td></td><td></td><td></td><td></td><td bgcolor='lightcyan'>[4,5]<br><b>Det</b> [0.28000]</td><td bgcolor='lightcyan'>[4,6]<br><b>NP</b> [0.01378]<br>&nbsp; (k=5, NP -> Det N [0.41])</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td bgcolor='lightcyan'>[5,6]<br><b>N</b> [0.12000]</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree(S, [Tree(NP, [Tree(Name, ['Jack'])]), Tree(VP, [Tree(V, ['saw']), Tree(NP, [Tree(NP, [Tree(Name, ['Bob'])]), Tree(PP, [Tree(P, ['with']), Tree(NP, [Tree(Det, ['my']), Tree(N, ['cookie'])])])])])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "toy_pcfg2 = nltk.grammar.PCFG.fromstring(\"\"\"\n",
    "    S    -> NP VP         [1.0]\n",
    "    VP   -> V NP          [.59]\n",
    "    VP   -> V             [.40]\n",
    "    VP   -> VP PP         [.01]\n",
    "    NP   -> Det N         [.41]\n",
    "    NP   -> Name          [.28]\n",
    "    NP   -> NP PP         [.31]\n",
    "    PP   -> P NP          [1.0]\n",
    "    V    -> 'saw'         [.21]\n",
    "    V    -> 'ate'         [.51]\n",
    "    V    -> 'ran'         [.28]\n",
    "    N    -> 'boy'         [.11]\n",
    "    N    -> 'cookie'      [.12]\n",
    "    N    -> 'table'       [.13]\n",
    "    N    -> 'telescope'   [.14]\n",
    "    N    -> 'hill'        [.5]\n",
    "    Name -> 'Jack'        [.52]\n",
    "    Name -> 'Bob'         [.48]\n",
    "    P    -> 'with'        [.61]\n",
    "    P    -> 'under'       [.39]\n",
    "    Det  -> 'the'         [.41]\n",
    "    Det  -> 'a'           [.31]\n",
    "    Det  -> 'my'          [.28]\n",
    "    \"\"\")\n",
    "\n",
    "import os\n",
    "path_to_gs = \"C:/Program Files/gs/gs9.21/bin/\"\n",
    "os.environ['PATH'] += os.pathsep + path_to_gs\n",
    "\n",
    "\n",
    "parse_CYK('Jack saw Bob with my cookie'.split(), toy_pcfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, feel free to investage NLTK's grammar and parsing algorithms. These live in `nltk.grammar`, `nltk.tree` and `nltk.parse`. Here's a good entry point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.grammar\n",
    "nltk.grammar.pcfg_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
